{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#"
      ],
      "id": "0ae27194-f4f2-49f9-a987-7dff98814156"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the range for the input data\n",
        "x = np.linspace(-10, 10, 100)\n",
        "import numpy as np\n",
        "\n",
        "def identity(x):\n",
        "    \"\"\"\n",
        "    Compute the Identity activation function.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : the input itself, unmodified.\n",
        "    \"\"\"\n",
        "    return x\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    \"\"\"\n",
        "    Compute the hyperbolic tangent of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : Hyperbolic tangent function output.\n",
        "    \"\"\"\n",
        "    return np.tanh(x)\n",
        "\n",
        "def relu(x):\n",
        "    \"\"\"\n",
        "    Compute the Rectified Linear Unit activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : ReLU function output where negative values are zero.\n",
        "    \"\"\"\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def leaky_relu(x, alpha=0.01):\n",
        "    \"\"\"\n",
        "    Compute the Leaky Rectified Linear Unit activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "    alpha : Slope of the negative part of the function.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : Leaky ReLU function output.\n",
        "    \"\"\"\n",
        "    return np.where(x > 0, x, x * alpha)\n",
        "\n",
        "def arctan(x):\n",
        "    \"\"\"\n",
        "    Compute the arctangent of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : ArcTan function output.\n",
        "    \"\"\"\n",
        "    return np.arctan(x)\n",
        "\n",
        "def softplus(x):\n",
        "    \"\"\"\n",
        "    Compute the Softplus activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : Softplus function output.\n",
        "    \"\"\"\n",
        "    return np.log1p(np.exp(x))\n",
        "\n",
        "def mish(x):\n",
        "    \"\"\"\n",
        "    Compute the Mish activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : Mish function output, derived as x * tanh(softplus(x)).\n",
        "    \"\"\"\n",
        "    return x * np.tanh(softplus(x))\n",
        "\n",
        "def selu(x, alpha=1.6732632423543772848170429916717, scale=1.0507009873554804934193349852946):\n",
        "    \"\"\"\n",
        "    Compute the Scaled Exponential Linear Unit activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "    alpha : Scale for the negative factor.\n",
        "    scale : Scale for the positive factor.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : SELU function output.\n",
        "    \"\"\"\n",
        "    return scale * np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
        "\n",
        "def silu(x):\n",
        "    \"\"\"\n",
        "    Compute the Sigmoid Linear Unit (SiLU) activation of x, also known as Swish.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : SiLU function output, derived as x / (1 + exp(-x)).\n",
        "    \"\"\"\n",
        "    return x / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Compute the SoftMax activation of x, typically used for multi-class classification.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : SoftMax function output.\n",
        "    \"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def softsign(x):\n",
        "    \"\"\"\n",
        "    Compute the SoftSign activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : SoftSign function output, derived as x / (1 + |x|).\n",
        "    \"\"\"\n",
        "    return x / (1 + np.abs(x))\n",
        "\n",
        "def elu(x, alpha=1.0):\n",
        "    \"\"\"\n",
        "    Compute the Exponential Linear Unit activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "    alpha : The scaling factor for negative inputs.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : ELU function output.\n",
        "    \"\"\"\n",
        "    return np.where(x >= 0, x, alpha * (np.exp(x) - 1))\n",
        "\n",
        "def prelu(x, alpha=0.01):\n",
        "    \"\"\"\n",
        "    Compute the Parametric Rectified Linear Unit activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "    alpha : The learned parameter that scales the output when x is negative.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : PReLU function output.\n",
        "    \"\"\"\n",
        "    return np.where(x >= 0, x, alpha * x)\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    Compute the Gaussian Error Linear Unit activation of x.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : GELU function output, derived using the Gaussian distribution function for smoothing.\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "def sqnl(x):\n",
        "    \"\"\"\n",
        "    Compute the Square Nonlinearity (SQNL) activation function.\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : SQNL function output, which is bounded between -1 and 1.\n",
        "    \"\"\"\n",
        "    return np.where(x > 2, 1, np.where(x >= 0, x - (x**2) / 4, np.where(x >= -2, x + (x**2) / 4, -1)))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    \"\"\"\n",
        "    Compute the Swish activation function, also known as the Sigmoid Linear Unit (SiLU).\n",
        "\n",
        "    Parameters:\n",
        "    x : A scalar or numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy array : Swish function output. The function is unbounded above and bounded below by zero.\n",
        "    \"\"\"\n",
        "    return x * sigmoid(x)\n"
      ],
      "id": "cell-0"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "rows = 3\n",
        "columns = 4\n",
        "\n",
        "\n",
        "plt.subplot(rows, columns, 1)\n",
        "plt.plot(x, identity(x), label=\"Identity\")\n",
        "plt.title(\"Identity\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 2)\n",
        "plt.plot(x, sigmoid(x), label=\"Sigmoid\")\n",
        "plt.title(\"Sigmoid\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 3)\n",
        "plt.plot(x, tanh(x), label=\"Tanh\")\n",
        "plt.title(\"Tanh\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 4)\n",
        "plt.plot(x, selu(x), label=\"SeLU\")\n",
        "plt.title(\"SeLU\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 5)\n",
        "plt.plot(x, softmax(x), label=\"SoftMax\")\n",
        "plt.title(\"SoftMax\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 6)\n",
        "plt.plot(x, softsign(x), label=\"SoftSign\")\n",
        "plt.title(\"SoftSign\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 7)\n",
        "plt.plot(x, mish(x), label=\"Mish\")\n",
        "plt.title(\"Mish\")\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.subplot(rows, columns, 8)\n",
        "plt.plot(x, swish(x), label=\"Swish\")\n",
        "plt.title(\"Swish\")\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.subplot(rows, columns, 9)\n",
        "plt.plot(x, arctan(x), label=\"arctan\")\n",
        "plt.title(\"ArcTan\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 10)\n",
        "plt.plot(x, silu(x), label=\"silu\")\n",
        "plt.title(\"SiLU\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 11)\n",
        "plt.plot(x, gelu(x), label=\"gelu\")\n",
        "plt.title(\"GeLU\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(rows, columns, 12)\n",
        "plt.plot(x, sqnl(x), label=\"SQNL\")\n",
        "plt.title(\"SQNL\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Add a legend\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "cell-fig-overview"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the activation functions as described previously\n",
        "# Define x as input values\n",
        "x = np.linspace(-10, 10, 200)\n"
      ],
      "id": "cell-2"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "\n",
        "plt.plot(x, identity(x), label=\"Identity\")\n",
        "plt.title(\"Identity Function\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.grid(True)"
      ],
      "id": "cell-fig-identity"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, sigmoid(x), label=\"Sigmoid\")\n",
        "plt.title(\"Sigmoid\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-sigmoid"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, tanh(x), label=\"Tanh\")\n",
        "plt.title(\"Tanh\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-tanh"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, arctan(x), label=\"Arctan\")\n",
        "plt.title(\"Arctan\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-arctan"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "# 3. Hyperbolic Tangent Functions\n",
        "plt.plot(x, softsign(x), label=\"SoftSign\")\n",
        "plt.title(\"SoftSign\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-softsign"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "# 3. Hyperbolic Tangent Functions\n",
        "plt.plot(x, softmax(x), label=\"SoftMax\")\n",
        "plt.title(\"SoftMax\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-softmax"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "# 3. Hyperbolic Tangent Functions\n",
        "plt.plot(x, softplus(x), label=\"SoftPlus\")\n",
        "plt.title(\"SoftPlus\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-softplus"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, relu(x), label=\"ReLU\")\n",
        "plt.plot(x, leaky_relu(x), label=\"Leaky ReLU\")\n",
        "plt.plot(x, prelu(x, 0.01), label=\"PReLU\")\n",
        "plt.plot(x, elu(x), label=\"ELU\")\n",
        "plt.plot(x, selu(x), label=\"SELU\")\n",
        "plt.title(\"ReLU and Variants\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "cell-fig-relu-variants"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, relu(x), label=\"ReLU\")\n",
        "plt.title(\"ReLU\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-relu"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, leaky_relu(x), label=\"Leaky ReLU\")\n",
        "plt.title(\"Leaky-ReLU\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-leaky_relu"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, prelu(x, 0.01), label=\"PReLU\")\n",
        "plt.title(\"PReLU\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-prelu"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, elu(x), label=\"ELU\")\n",
        "plt.title(\"ELU\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-elu"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, silu(x), label=\"SILU\")\n",
        "plt.title(\"SILU\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-silu"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, selu(x), label=\"SELU\")\n",
        "plt.title(\"SELU\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-selu"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, gelu(x), label=\"GeLU\")\n",
        "plt.title(\"GeLU\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "cell-fig-gelu"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, mish(x), label=\"Mish\")\n",
        "plt.title(\"Mish\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-mish"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, swish(x), label=\"Swish\")\n",
        "plt.title(\"Swish\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cell-fig-swish"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "plt.plot(x, sqnl(x), label=\"SQNL\")\n",
        "plt.title(\"SQNL\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "cell-fig-sqnl"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "# 5. Advanced Non-linear Functions\n",
        "plt.plot(x, mish(x), label=\"Mish\")\n",
        "plt.plot(x, sqnl(x), label=\"SQNL\")\n",
        "plt.plot(x, gelu(x), label=\"GeLU\")\n",
        "plt.title(\"Advanced Non-linear Functions\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "cell-fig-nonlinear"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "# Corrected Maxout function\n",
        "def maxout_demo(x):\n",
        "    weights = np.array([[1, -0.5], [0.5, 1]])  # Two sets of weights for two neurons\n",
        "    biases = np.array([0.5, -0.5])  # Biases for each set\n",
        "    x_reshaped = np.tile(x, (2, 1)).T  # Duplicate x to match weight shape\n",
        "    neuron_outputs = np.dot(x_reshaped, weights.T) + biases\n",
        "    return np.max(neuron_outputs, axis=1)\n",
        "\n",
        "# Plotting the activation functions\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(x, maxout_demo(x), label=\"Maxout\")\n",
        "plt.title(\"Maxout\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "cell-fig-maxout"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": ".venv",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  }
}